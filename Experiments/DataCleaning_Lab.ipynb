{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import *\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(1)\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "#python -m spacy download corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df_loading():\n",
    "    d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 10\")\n",
    "    df = pd.DataFrame(d)\n",
    "    print(df)\n",
    "\n",
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 10\")\n",
    "df = pd.DataFrame(d)\n",
    "corpus_a = \"fr_dep_news_trf\"\n",
    "corpus_e = \"fr_core_news_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def separe_to_sentences(text, efficiency = True):\n",
    "    corpus = corpus_e if efficiency else corpus_a\n",
    "    nlp = spacy.load(corpus)\n",
    "    doc = nlp(text)\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    return [unicodedata.normalize(\"NFKD\", sent.text)  for sent in doc.sents]\n",
    "\n",
    "def process_text(text, efficiency = True):\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    corpus = corpus_e if efficiency else corpus_a\n",
    "    nlp = spacy.load(corpus)\n",
    "    doc = nlp(text)\n",
    "    t = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return t\n",
    "\n",
    "def create_lexic(d2, size = 1000):\n",
    "    df2 = pd.DataFrame(d2)\n",
    "    df2[\"cleaned_text\"] = df2[\"text\"].apply(process_text)\n",
    "    df2[\"n_words\"] = df2[\"cleaned_text\"].apply(len)\n",
    "    df2 = df2[df2.n_words > 1]\n",
    "    c = dict(Counter(df2[\"cleaned_text\"].sum()))\n",
    "    so = sorted(c.items(), key = lambda x:x[1], reverse = True)\n",
    "    d = dict(so[:size])\n",
    "    return list(d.keys())\n",
    "\n",
    "\n",
    "    \n",
    "def separe_dictionnary_by_sentences(d):\n",
    "    d2 = {k:[] for k in d.keys()}\n",
    "    for nom, text, x, y in tqdm(list(zip(d[\"nom\"], d[\"text\"], d[\"x\"], d[\"y\"]))):\n",
    "        sentences = separe_to_sentences(text, efficiency = True)\n",
    "        for sentence in sentences:\n",
    "            if len(sentences) < 15:\n",
    "                continue\n",
    "            d2[\"nom\"].append(nom)\n",
    "            d2[\"x\"].append(x)\n",
    "            d2[\"y\"].append(y)\n",
    "            d2[\"text\"].append(sentence)\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 10\")\n",
    "df = pd.DataFrame(d)\n",
    "lexic = create_lexic(d, size = 1000)\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(process_text)\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda x:[i for i in x if i in lexic])\n",
    "df[\"text\"] = df[\"cleaned_text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8337b",
   "metadata": {},
   "source": [
    "## Without embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 100\")\n",
    "df = pd.DataFrame(d)\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(process_text)\n",
    "lexic = create_lexic(d, size = 1000)\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda x:[i for i in x if i in lexic])\n",
    "df[\"text\"] = df[\"cleaned_text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(list(df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.transform([df[\"text\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df047fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF_NN(nn.Module):\n",
    "\n",
    "    def __init__(self, vect, hidden_size = 100):\n",
    "        super(TFIDF_NN, self).__init__()\n",
    "        self.vectorizer = vect\n",
    "        vocab_size = vect.get_feature_names_out().shape[0]\n",
    "        self.linear1 = nn.Linear(vocab_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 2)\n",
    "\n",
    "\n",
    "    def forward(self, text):\n",
    "        inputs = torch.tensor(self.vectorizer.transform(text).toarray()).float()\n",
    "        h1 = F.relu(self.linear1(inputs))\n",
    "        output = self.output(h1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11454403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFIDF_NN(vectorizer)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(10000):\n",
    "    y_pred = model(df[\"text\"])\n",
    "    y_true = torch.tensor(np.array(df[[\"x\", \"y\"]])).float()\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "    if t % 250 == 0:\n",
    "        print(t, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "torch.save(model.state_dict(), 'model_no_embeding.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702e129",
   "metadata": {},
   "source": [
    "## Sans préprocessing\n",
    "Parce que ça prend putain de trop de temps bordel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 50000\")\n",
    "df = pd.DataFrame(d)\n",
    "### Je désactive le préprocessing pour povuoir tester plus de députés\n",
    "#df[\"cleaned_text\"] = df[\"text\"].apply(process_text)\n",
    "#lexic = create_lexic(d, size = 1000)\n",
    "#df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda x:[i for i in x if i in lexic])\n",
    "#df[\"text\"] = df[\"cleaned_text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(list(df[\"text\"]))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1949cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFIDF_NN(vectorizer)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in tqdm(range(5000)):\n",
    "    y_pred = model(df[\"text\"])\n",
    "    y_true = torch.tensor(np.array(df[[\"x\", \"y\"]])).float()\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "    if t % 200 == 0:\n",
    "        print(t)\n",
    "        print(\"Training: \", loss.item())\n",
    "        d2 = df.sample(n=100)\n",
    "        yt = torch.tensor(np.array(d2[[\"x\", \"y\"]])).float()\n",
    "        pt = model(d2[\"text\"])\n",
    "        loss2 = loss_fn(yt, pt)\n",
    "        print(\"Test: \", loss2.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "torch.save(model.state_dict(), 'model_embeding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acde3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = \"\"\"\n",
    "La crise aurait pu être l’occasion de remettre en question le bien-fondé de la croissance du trafic aérien. Après tout, un trajet en avion – vous le savez, monsieur le ministre délégué – est en moyenne quatorze à quarante fois plus polluant qu’en train. Le trafic aérien double tous les quinze ans et la filière est responsable de plus de 7 % de l’empreinte carbone de la France. Peut-être serait-il alors plus sage d’amorcer la bifurcation écologique ? Mais non ! Saupoudrez comme il vous plaira, et sans garanties écologiques.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "depute_df = get_df(\"SELECT nom, x, y from deputes\")\n",
    "depute_df = pd.DataFrame(depute_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ab12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(depute_df[\"x\"], depute_df[\"y\"], c = \"blue\")\n",
    "o = model([ex]).detach().numpy()[0]\n",
    "x,y = o[0], o[1]\n",
    "plt.scatter([x],[y], c = \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0226f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
